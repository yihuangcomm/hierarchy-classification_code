\documentclass[conference]{IEEEtran}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[australian]{babel}
\usepackage{color,xcolor}
\usepackage{listings}
\usepackage{subfigure}
\usepackage{graphicx}
\usepackage{url}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{booktabs}
\usepackage{xspace}
\usepackage{verbatim}
%\usepackage{footnote}
\usepackage{epstopdf}
% \usepackage{threeparttable}
%\usepackage[keeplastbox]{flushend}
\usepackage{mathtools}
%\usepackage{flushend}



% \usepackage{algpseudocode}

%\newcommand{\theTitle}{Endpoint-transparent Multipath Transport with
%Software-defined Networks}
\graphicspath{ {images/} }
\lefthyphenmin 12
\righthyphenmin 12

\newcommand{\guillaume}[1]{{\em\color{red}[[GJ: #1]]}}
\newcommand{\kt}[1]{{\em\color{blue}[[KT: #1]]}}
\newcommand{\solution}{{\em Deep Content}}

\title{\solution: Unveiling Video Streaming Content From Encrypted WiFi Traffic}

\author{
	\IEEEauthorblockN{
		Ying Li,\IEEEauthorrefmark{1}
		Yi Huang,\IEEEauthorrefmark{1}
		Suranga Seneviratne,\IEEEauthorrefmark{4}
		Kanchana Thilakarathna,\IEEEauthorrefmark{4}
		Adriel Cheng,\IEEEauthorrefmark{2} \\
		Guillaume Jourjon,\IEEEauthorrefmark{3}
		Darren Webb,\IEEEauthorrefmark{2} and
		Richard Xu\IEEEauthorrefmark{1}
	}\\
	\IEEEauthorblockA{
		\IEEEauthorrefmark{1} University Technology of Sydney, Australia; Email: \{ying.li-11, yi.huang-3,yida.xu\}@uts.edu.au \\
		\IEEEauthorrefmark{2} Defence Science \& Technology Group, Edinburgh, Australia; Email: \{firstname.lastname\}@dst.defence.gov.au \\
		\IEEEauthorrefmark{3} Data61-CSIRO, Sydney, Australia; Email: guillaume.jourjon@data61.csiro.au \\
		\IEEEauthorrefmark{4} University of Sydney, Australia; Email: \{firstname.lastname\}@sydney.edu.au
	}
}

\begin{document}
	\maketitle
	
	\begin{abstract}
%dlw-Beyond video streaming providers such as YouTube or Netflix, many other online applications are dominated by videos as well, e.g. social networking tools like Facebook or Twitter feeds. 
% From AOC
The proliferation of smart devices has led to an exponential growth in digital media consumption, especially mobile video for content marketing. The vast majority of the associated Internet traffic is now end-to-end encrypted, and while encryption provides better user privacy and security, it has made network surveillance an impossible task. The result is an unchecked environment for exploiters and attackers to distribute content such as fake, radical and propaganda videos.
 
Recent advances in machine learning techniques have shown great promise in characterising encrypted traffic captured at the end points. However, video fingerprinting from passively listening to encrypted traffic, especially wireless traffic, has been reported as a challenging task due to the difficulty in distinguishing retransmissions and multiple flows on the same link. We show the potential of fingerprinting videos by passively sniffing WiFi frames in air, even without connecting to the WiFi network. We have developed Multi-Layer Perceptron (MLP) and Recurrent Neural Networks (RNNs) that are able to identify streamed YouTube videos from a closed set, by sniffing WiFi traffic encrypted at both Media Access Control (MAC) and Network layers. We compare these models to the state-of-the-art wired traffic classifier based on Convolutional Neural Networks (CNNs), and show that our models obtain similar results while requiring significantly less computational power and time (threefold reduction). 

	\end{abstract}

	
	\input{introduction}
	
	\input{background}
	
	\input{related}
	
	\input{experiment}
		
	\input{architecture}
			
	\input{results}	
	
	
	
	\input{conclusion}
	
	\section*{Acknowledgements}
	This work was conducted in partnership with the Defence Science \& Technology Group and Data61/CSIRO, through the Next Generation Technologies Program.
	
	\bibliographystyle{IEEEtran}
	\bibliography{bibliography}
	
	\appendix
	%\section*{List of YouTube Video}
	
	We present in Table~\ref{table:videos} the list of videos used in this article as well as their category as per YouTube metadata. 
	
	\begin{table}[h!]
\centering
\caption{List of YouTube Video}
\label{table:videos}
\begin{tabular}{ lllll  }
 \toprule
  \textbf{Video ID} & \textbf{YouTube ID}&\textbf{Video Category} &\textbf{Length} &\textbf{HD}\\
 \midrule
%\url{https://www.youtube.com/watch?v=
Video 1 & d853h-8rsPQ & Entertainment & 11:11 & Yes\\
Video 2 & sywaPf021oE & Sports & 13:27 & Yes\\
Video 3 & 6rzlfG6Xkg0 & Sports & 5:31 & Yes\\
Video 4 & 95M8W1JgH\_0 & Entertainment & 5:03 & Yes\\
Video 5 & QU1byle-nmA & Sports & 7:21 & Yes\\
Video 6 & gPHVLxm8U-0 & Entertainment & 5:12 & Yes\\
Video 7 & C3ap6S4mAco & Music& 4:09 & Yes\\
Video 8 & kbMqWXnpXcA & Music& 6:05 & Yes\\
Video 9 & XruwUFiK8YA & How-to \& Style& 10:03 & Yes\\
Video 10 & 4bPezggGBa8 & Comedy & 4:53 & Yes\\
 \bottomrule
\end{tabular}
%\end{center}
\end{table}

Finally, we summarise in Table~\ref{table:parameters} the various neural networks parameters that we used across the three models.
	\begin{table}[h!]
\centering
\caption{List of neural networks parameters}
\label{table:parameters}
\begin{tabular}{  ll   }
 \toprule
  \textbf{Parameter Name}&\textbf{Value} \\
 \midrule
learning rate & 0.0001\\
batch size & 64\\
activation & RELU\\
optimiser & Adam\\
Batch Normalisation decay & 0.5\\
Batch Normalisation epsilon & 0.001\\
 \bottomrule
\end{tabular}
%\end{center}
\end{table}
	
\end{document}